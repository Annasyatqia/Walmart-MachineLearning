# -*- coding: utf-8 -*-
"""A Machine Learning Approach for Analyzing and Predicting Consumer Behavior Patterns in Walmart Transaction Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19042Reg9TfCL_Kxl_cBRU-SYNWM96xdI
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

file_path = "/content/drive/MyDrive/WALMARTDATASET/Walmart_customer_purchases.csv"

df = pd.read_csv(file_path)
df.head()

import seaborn as sns
import matplotlib.pyplot as plt

# Count plot for product categories
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='Category')
plt.title("Jumlah Pembelian per Kategori Produk")
plt.xticks(rotation=45)
plt.show()

# Box plot for purchase amount by gender
plt.figure(figsize=(8, 6))
sns.violinplot(data=df, x='Gender', y='Purchase_Amount', inner='quartile')
plt.title("Distribusi Jumlah Pembelian per Gender (Violin Plot)")
plt.show()

# ğŸ§¹ 4. DATA PREPROCESSING

from sklearn.preprocessing import LabelEncoder

df = df.dropna()

le = LabelEncoder()
categorical_cols = ['Gender', 'City', 'Category', 'Payment_Method', 'Discount_Applied', 'Repeat_Customer']

for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

# ğŸ“ˆ 5. PREDIKSI TREN â€“ REGRESI

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder
import numpy as np
import matplotlib.pyplot as plt

# ğŸ§  Pilih fitur & target
X = df[['Gender', 'Age', 'City', 'Category', 'Payment_Method', 'Discount_Applied', 'Rating', 'Repeat_Customer']]
y = df['Purchase_Amount']

# âœ‚ï¸ Split data training & testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ¯ Training model Random Forest Regressor
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# ğŸ”® Prediksi
predictions = model.predict(X_test)

# ğŸ“ Evaluasi dengan RMSE
rmse = np.sqrt(mean_squared_error(y_test, predictions))
print("Root Mean Squared Error (RMSE):", rmse)

from sklearn.linear_model import LinearRegression

lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
lr_preds = lr_model.predict(X_test)

lr_rmse = np.sqrt(mean_squared_error(y_test, lr_preds))
print("Linear Regression RMSE:", lr_rmse)

# ğŸ“Š Visualisasi 1 â€“ Actual vs Predicted

plt.figure(figsize=(8, 6))
plt.hexbin(x=y_test, y=predictions, gridsize=50, cmap='Blues', bins='log')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Purchase Amount")
plt.ylabel("Predicted Purchase Amount")
plt.title("Actual vs Predicted Purchase Amount (Hexbin Plot)")
plt.colorbar(label='log(count)')
plt.grid(True)
plt.show()

# ğŸ“Š Visualisasi 2 â€“ Feature Importance

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.cm as cm

# Urutkan feature importance
importances = model.feature_importances_
feature_names = X.columns
feature_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=True)

colors = cm.Blues(np.linspace(0.4, 0.9, len(feature_df)))
# Plot
plt.figure(figsize=(8, 5))
sns.barplot(data=feature_df, x='Importance', y='Feature', palette=colors)
plt.title("Feature Importance in Random Forest Regressor")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 8))
corr_matrix = df.corr(numeric_only=True)
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Matrix")
plt.show()

# ğŸ§  6. SEGMENTASI â€“ CLUSTERING

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Step 1: Aggregate total pembelian & rata-rata umur per customer
cluster_df = df.groupby("Customer_ID").agg({
    "Purchase_Amount": "sum",
    "Age": "mean"
}).reset_index()

# Step 2: Standarisasi fitur
scaler = StandardScaler()
scaled_features = scaler.fit_transform(cluster_df[['Purchase_Amount', 'Age']])

# Step 3: Clustering
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
cluster_df['Cluster'] = kmeans.fit_predict(scaled_features)

summary = cluster_df.groupby('Cluster').agg({
    'Purchase_Amount': ['mean', 'min', 'max'],
    'Age': ['mean', 'min', 'max'],
    'Customer_ID': 'count'
})
summary.columns = ['_'.join(col) for col in summary.columns]
print(summary)

# ğŸ“Š Visualisasi 3 â€“ Clustering Scatter Plot

plt.figure(figsize=(8, 5))
sns.scatterplot(
    data=cluster_df,
    x='Age', y='Purchase_Amount',
    hue='Cluster',
    palette='Set2',
    alpha=0.6,
    s=50
)
plt.title("Customer Segmentation by Age and Total Purchase")
plt.xlabel("Average Age")
plt.ylabel("Total Purchase Amount")
plt.grid(True)
plt.legend(title='Cluster')
plt.tight_layout()
plt.show()

# ğŸ“Š Visualisasi 4 â€“ Clustering + Centroids

# Step 1: Dapatkan koordinat pusat cluster dalam skala asli
centroids = scaler.inverse_transform(kmeans.cluster_centers_)

# Step 2: Plot scatter dan centroids
plt.figure(figsize=(8, 6))
sns.scatterplot(
    data=cluster_df,
    x='Purchase_Amount', y='Age',
    hue='Cluster', palette='Set2', alpha=0.6
)
plt.scatter(
    centroids[:, 0], centroids[:, 1],
    s=200, c='black', marker='X', label='Centroids'
)
plt.title("K-Means Clustering with Centroids")
plt.xlabel("Total Purchase Amount")
plt.ylabel("Average Age")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()